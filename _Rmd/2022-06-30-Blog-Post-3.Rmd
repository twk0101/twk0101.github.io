---
title: "Blog Post 3"
author: "Tommy King"
date: "`r Sys.Date()`"
---

# Cool R Stuff  
  
There are indeed many cool things about R, but I think my favorite among them was actually something I just learned earlier today while finishing up the regression homework. I have not had much exposure to the `caret` package but being able to do so many steps of model building within a single function call seems like a real game changer to me. In comparison to doing the same process in Python, this method seems much more elegant and easier. In general R's reliance on packages that have so many co-dependencies is a little frustrating at times but for outcomes like this where it really cuts down on the work time, I definitely think it seems worth it. In the code chunk below, I use an example kind of like the one we used in the homework to train a model with cross validation and then make predictions.  
  
```{r example_code, eval=TRUE, echo=TRUE}
library(caret)

# Reading in the dataset from before
raw_data <- readr::read_csv("SeoulBikeData.csv", locale = readr::locale(encoding = "latin1"))
bikes <- raw_data[,2:14]

train_index <- createDataPartition(bikes$`Rented Bike Count`, p = .8, list = FALSE)

bike_train <- bikes[train_index, ]
bike_test <- bikes[-train_index, ]

model <- train(`Rented Bike Count` ~., data=bike_train, method = "lm", 
            preProcess = c("center", "scale"), trControl = trainControl(method = "cv", number = 5))

data.frame(t(model$results))

pred <- predict(model, newdata = bike_test)

postResample(pred, obs = bike_test$`Rented Bike Count`)

```

